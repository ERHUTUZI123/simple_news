from sqlalchemy.orm import Session
from sqlalchemy import desc, asc
from app.models import News, Vote, SavedArticle, User
from app.scoring import calculate_news_score, extract_keywords_from_text, build_existing_keyword_map
from sqlalchemy.exc import NoResultFound
from sqlalchemy import func
from datetime import datetime
from typing import List, Dict, Any
from dateutil import parser as dateparser
from dateutil import tz
from app import redis_client
import json
from uuid import UUID
from sqlalchemy.sql import text
import re
import uuid
from app.smart_scoring import compute_smart_score, get_score_breakdown

class PostgresService:
    def __init__(self, db: Session):
        self.db = db

    # è·å–æ–°é—»
    def get_news(self, offset=0, limit=20, sort_by="smart", source_filter=None) -> List[Dict]:
        """è·å–æ–°é—»ï¼Œæ”¯æŒæ™ºèƒ½æ’åºï¼Œä»…ç¼“å­˜é¦–é¡µæ•°æ®ï¼ˆoffset=0ï¼‰"""
        try:
            use_cache = (offset == 0)
            cache_key = f"news:{sort_by}:{offset}:{limit}:{source_filter or 'all'}"
            if use_cache:
                cached = redis_client.get(cache_key)
                if cached:
                    return json.loads(cached)
            
            print(f"ğŸ” DEBUG: Querying news with offset={offset}, limit={limit}, sort_by={sort_by}")
            
            query = self.db.query(News)
            
            # åº”ç”¨æ¥æºè¿‡æ»¤
            if source_filter:
                query = query.filter(News.source.ilike(f"%{source_filter}%"))
            
            # åº”ç”¨æ’åº
            if sort_by == "smart_score":
                # æ™ºèƒ½è¯„åˆ†æ’åºï¼šæŒ‰smart_scoreé™åº
                query = query.order_by(desc(News.smart_score))
            elif sort_by == "smart":
                # æ™ºèƒ½æ’åºï¼šæŒ‰ç»¼åˆè¯„åˆ†é™åº
                query = query.order_by(desc(News.score))
            elif sort_by == "time":
                # æ—¶é—´æ’åºï¼šæŒ‰å‘å¸ƒæ—¶é—´é™åº
                query = query.order_by(desc(News.published_at))
            elif sort_by == "headlines":
                # ç‚¹èµæ•°æ’åºï¼šæŒ‰ç‚¹èµæ•°é™åº
                query = query.order_by(desc(News.headline_count))
            else:
                # é»˜è®¤ä½¿ç”¨æ™ºèƒ½è¯„åˆ†æ’åº
                query = query.order_by(desc(News.smart_score))
            
            # åº”ç”¨åˆ†é¡µ
            news_items = query.offset(offset).limit(limit).all()
            
            print(f"ğŸ” DEBUG: Found {len(news_items)} news items in database")
            
            # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
            results = []
            for item in news_items:
                try:
                    # ç¡®ä¿æ—¥æœŸæ ¼å¼æ­£ç¡®
                    date_str = None
                    published_at = item.published_at
                    if published_at:
                        try:
                            # ç¡®ä¿æ˜¯UTCæ—¶é—´å¹¶æ ¼å¼åŒ–ä¸ºISOå­—ç¬¦ä¸²
                            if published_at.tzinfo is None:
                                # å¦‚æœæ²¡æœ‰æ—¶åŒºä¿¡æ¯ï¼Œå‡è®¾æ˜¯UTC
                                date_str = published_at.isoformat() + 'Z'
                            else:
                                # å¦‚æœæœ‰æ—¶åŒºä¿¡æ¯ï¼Œè½¬æ¢ä¸ºUTC
                                from datetime import timezone
                                utc_date = published_at.astimezone(timezone.utc)
                                date_str = utc_date.isoformat()
                        except Exception as e:
                            print(f"Error formatting date: {e}")
                            date_str = datetime.utcnow().isoformat() + 'Z'
                    else:
                        date_str = datetime.utcnow().isoformat() + 'Z'
                    
                    result_item = {
                        "id": str(item.id),  # Convert UUID to string
                        "title": item.title,
                        "content": item.content,
                        "link": item.link,
                        "date": date_str,
                        "source": item.source,
                        "vote_count": self.get_vote_count(item.title),
                        "score": float(item.score) if item.score is not None else 0.0,  # Ensure float
                        "smart_score": float(item.smart_score) if item.smart_score is not None else 0.0,  # æ™ºèƒ½è¯„åˆ†
                        "keywords": self._ensure_keywords_array(item.keywords)
                    }
                    results.append(result_item)
                    print(f"ğŸ” DEBUG: Added item: {item.title[:50]}...")
                except Exception as e:
                    print(f"âŒ Error processing news item: {e}")
                    continue
            
            print(f"ğŸ” DEBUG: Returning {len(results)} processed items")
            
            if use_cache:
                try:
                    redis_client.setex(cache_key, 600, json.dumps(results, ensure_ascii=False))
                except Exception as e:
                    print(f"âš ï¸ Cache save failed: {e}")
            
            return results
        except Exception as e:
            print(f"âŒ Error getting news: {e}")
            import traceback
            traceback.print_exc()
            return []

    # ä¿å­˜æ–°é—»
    def save_news(self, news_items: List[Dict]) -> bool:
        """ä¿å­˜æ–°é—»åˆ°æ•°æ®åº“ï¼ŒåŒ…å«æ™ºèƒ½è¯„åˆ†"""
        try:
            print(f"ğŸ” DEBUG: Saving {len(news_items)} news items to database")
            
            if not news_items:
                print("âš ï¸ No news items to save")
                return True
            
            saved_count = 0
            for i, item in enumerate(news_items):
                try:
                    # åŸºæœ¬éªŒè¯
                    if not item.get("title") or not item.get("content") or not item.get("link"):
                        print(f"âš ï¸ Skipping item {i}: missing required fields")
                        continue
                    
                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼ˆåªæ£€æŸ¥æ ‡é¢˜ï¼‰
                    existing = self.db.query(News).filter(News.title == item["title"]).first()
                    if existing:
                        print(f"ğŸ” DEBUG: Skipping existing article: {item['title'][:50]}...")
                        continue
                    
                    # æå–å…³é”®è¯
                    try:
                        keywords = extract_keywords_from_text(item["title"] + " " + item["content"])
                    except Exception as e:
                        print(f"âš ï¸ Keyword extraction failed for item {i}: {e}")
                        keywords = []
                    
                    # æ ‡å‡†åŒ–æ—¥æœŸå¤„ç†
                    raw_date = item.get("date", "")
                    try:
                        if isinstance(raw_date, str):
                            # è§£æRSSæ—¥æœŸå­—ç¬¦ä¸²å¹¶è½¬æ¢ä¸ºUTCæ—¶é—´
                            from dateutil import parser as dateparser
                            from dateutil import tz
                            parsed_date = dateparser.parse(raw_date)
                            if parsed_date.tzinfo:
                                # å¦‚æœæœ‰æ—¶åŒºä¿¡æ¯ï¼Œè½¬æ¢ä¸ºUTC
                                utc_date = parsed_date.astimezone(tz.tzutc())
                                normalized_date = utc_date.replace(tzinfo=None)
                            else:
                                # å¦‚æœæ²¡æœ‰æ—¶åŒºä¿¡æ¯ï¼Œå‡è®¾æ˜¯UTC
                                normalized_date = parsed_date
                        else:
                            normalized_date = raw_date
                    except Exception as e:
                        print(f"âš ï¸ Date parsing failed for item {i}: {e}")
                        from datetime import datetime
                        normalized_date = datetime.utcnow()
                    
                    # åˆ›å»ºAIæ‘˜è¦ç»“æ„
                    summary_ai = {
                        "brief": "",
                        "detailed": "",
                        "structure_score": 3.0  # é»˜è®¤è¯„åˆ†
                    }
                    
                    # è®¡ç®—ç»¼åˆè¯„åˆ†
                    try:
                        score = calculate_news_score(
                            published_at=normalized_date,
                            summary_ai=summary_ai,
                            source=item.get("source", ""),
                            keywords=keywords,
                            headline_count=0,  # æ–°æ–°é—»åˆå§‹ç‚¹èµæ•°ä¸º0
                            existing_keyword_map={}  # ç®€åŒ–ï¼Œä¸ä½¿ç”¨ç°æœ‰å…³é”®è¯æ˜ å°„
                        )
                    except Exception as e:
                        print(f"âš ï¸ Score calculation failed for item {i}: {e}")
                        score = 1.0  # é»˜è®¤è¯„åˆ†
                    
                    # è®¡ç®—æ™ºèƒ½è¯„åˆ†
                    try:
                        # è·å–ç°æœ‰æ–°é—»ç”¨äºæ–°é¢–æ€§è®¡ç®—
                        existing_news = self.get_news(0, 1000, "time")
                        existing_titles = [news.get('title', '') for news in existing_news]
                        
                        # å‡†å¤‡æ–‡ç« æ•°æ®ç”¨äºè¯„åˆ†
                        article_data = {
                            'title': item["title"],
                            'content': item["content"],
                            'source': item.get("source", ""),
                            'published_at': normalized_date,
                            'headline_count': 0,
                            'summary_ai': summary_ai
                        }
                        
                        # è®¡ç®—æ™ºèƒ½è¯„åˆ†
                        smart_score = compute_smart_score(article_data, existing_news)
                        
                        # å¯é€‰ï¼šè·å–è¯¦ç»†è¯„åˆ†åˆ†è§£ï¼ˆç”¨äºè°ƒè¯•ï¼‰
                        score_breakdown = get_score_breakdown(article_data, existing_news)
                        print(f"ğŸ” DEBUG: Smart score breakdown for '{item['title'][:50]}...': {score_breakdown}")
                        
                    except Exception as e:
                        print(f"âš ï¸ Error computing smart score: {e}")
                        smart_score = 0.0
                    
                    # åˆ›å»ºæ–°é—»å¯¹è±¡
                    news = News(
                        id=str(uuid.uuid4()),
                        title=item["title"],
                        content=item["content"],
                        summary=item.get("summary", ""),
                        link=item["link"],
                        date=normalized_date,
                        source=item.get("source", ""),
                        published_at=normalized_date,
                        summary_ai=summary_ai,
                        headline_count=0,
                        keywords=keywords,
                        score=score,
                        smart_score=smart_score  # æ·»åŠ æ™ºèƒ½è¯„åˆ†
                    )
                    
                    self.db.add(news)
                    self.db.commit()
                    saved_count += 1
                except Exception as e:
                    self.db.rollback()
                    print(f"âŒ Error saving individual article {i}: {e}")
                    continue
            
            # æœ€ç»ˆæäº¤
            self.db.commit()
            print(f"ğŸ” DEBUG: Successfully saved {saved_count} new articles to database")
            return True
        except Exception as e:
            print(f"âŒ Error saving news: {e}")
            import traceback
            traceback.print_exc()
            self.db.rollback()
            return False

    # è·å–æŠ•ç¥¨æ•°
    def get_vote_count(self, title: str) -> int:
        """è·å–æŠ•ç¥¨æ•°"""
        try:
            vote = self.db.query(Vote).filter(Vote.title == title).first()
            return int(getattr(vote, "count", 0)) if vote else 0
        except Exception as e:
            print(f"Error getting vote count: {e}")
            return 0

    # æ›´æ–°æŠ•ç¥¨
    def update_vote(self, title: str, delta: int) -> int:
        """æ›´æ–°æŠ•ç¥¨æ•°"""
        try:
            vote = self.db.query(Vote).filter(Vote.title == title).first()
            if not vote:
                vote = Vote(title=title, count=delta)
                self.db.add(vote)
            else:
                current_count = int(getattr(vote, "count", 0))
                new_count = max(0, current_count + delta)
                setattr(vote, "count", new_count)
            
            # åŒæ—¶æ›´æ–°æ–°é—»çš„headline_count
            news = self.db.query(News).filter(News.title == title).first()
            if news:
                news.headline_count = int(getattr(vote, "count", 0))
                # é‡æ–°è®¡ç®—è¯„åˆ†
                self._recalculate_news_score(news)
            
            self.db.commit()
            return int(getattr(vote, "count", 0))
        except Exception as e:
            print(f"Error updating vote: {e}")
            self.db.rollback()
            return 0

    def _recalculate_news_score(self, news: News):
        """é‡æ–°è®¡ç®—æ–°é—»è¯„åˆ†"""
        try:
            # è·å–ç°æœ‰æ–°é—»çš„å…³é”®è¯æ˜ å°„
            existing_news = self.get_news(0, 1000, "time")
            existing_keyword_map = build_existing_keyword_map(existing_news)
            
            # é‡æ–°è®¡ç®—è¯„åˆ†
            published_at = news.published_at or datetime.utcnow()
            summary_ai = news.summary_ai or {}
            keywords = news.keywords or []
            headline_count = news.headline_count or 0
            
            score = calculate_news_score(
                published_at=published_at,
                summary_ai=summary_ai,
                source=news.source,
                keywords=keywords,
                headline_count=headline_count,
                existing_keyword_map=existing_keyword_map
            )
            
            news.score = score
        except Exception as e:
            print(f"Error recalculating score: {e}")

    def update_ai_summary(self, title: str, brief_summary: str, detailed_summary: str, structure_score: float = 3.0):
        """æ›´æ–°AIæ‘˜è¦å’Œç»“æ„è¯„åˆ†"""
        try:
            news = self.db.query(News).filter(News.title == title).first()
            if news:
                news.summary_ai = {
                    "brief": brief_summary,
                    "detailed": detailed_summary,
                    "structure_score": structure_score
                }
                # é‡æ–°è®¡ç®—è¯„åˆ†
                self._recalculate_news_score(news)
                self.db.commit()
        except Exception as e:
            print(f"Error updating AI summary: {e}")
            self.db.rollback()

    def get_article_by_title(self, title: str) -> Dict:
        """æ ¹æ®æ ‡é¢˜è·å–æ–‡ç« ï¼Œå¸¦ç¼“å­˜"""
        try:
            # æ„é€ ç¼“å­˜key
            cache_key = f"article:{title}"
            cached = redis_client.get(cache_key)
            if cached:
                return json.loads(cached)
            
            # ç›´æ¥æŸ¥è¯¢æ•°æ®åº“
            news = self.db.query(News).filter(News.title == title).first()
            
            if news:
                # ç¡®ä¿æ—¥æœŸæ ¼å¼æ­£ç¡®
                date_str = None
                published_at = news.published_at
                if published_at:
                    try:
                        # ç¡®ä¿æ˜¯UTCæ—¶é—´å¹¶æ ¼å¼åŒ–ä¸ºISOå­—ç¬¦ä¸²
                        if published_at.tzinfo is None:
                            # å¦‚æœæ²¡æœ‰æ—¶åŒºä¿¡æ¯ï¼Œå‡è®¾æ˜¯UTC
                            date_str = published_at.isoformat() + 'Z'
                        else:
                            # å¦‚æœæœ‰æ—¶åŒºä¿¡æ¯ï¼Œè½¬æ¢ä¸ºUTC
                            from datetime import timezone
                            utc_date = published_at.astimezone(timezone.utc)
                            date_str = utc_date.isoformat()
                    except Exception as e:
                        print(f"Error formatting date: {e}")
                        date_str = datetime.utcnow().isoformat() + 'Z'
                else:
                    date_str = datetime.utcnow().isoformat() + 'Z'
                
                result = {
                    "id": str(news.id),  # Convert UUID to string
                    "title": news.title,
                    "content": news.content,  # Frontend expects 'content'
                    "link": news.link,
                    "date": date_str,  # Frontend expects 'date'
                    "source": news.source,
                    "vote_count": self.get_vote_count(news.title),
                    "score": float(news.score) if news.score is not None else 0.0,
                    "keywords": self._ensure_keywords_array(news.keywords)
                }
                
                # è®¾ç½®ç¼“å­˜ï¼Œ600ç§’
                redis_client.setex(cache_key, 600, json.dumps(result, ensure_ascii=False))
                return result
            
            # æ²¡æ‰¾åˆ°æ–‡ç« 
            result = {"error": "Article not found"}
            redis_client.setex(cache_key, 600, json.dumps(result, ensure_ascii=False))
            return result
        except Exception as e:
            print(f"Error getting article by title: {e}")
            return {"error": "Article not found"}

    def _ensure_keywords_array(self, keywords: Any) -> List[str]:
        """ç¡®ä¿å…³é”®è¯æ˜¯æ•°ç»„ï¼Œå¤„ç†å„ç§å¯èƒ½çš„æ ¼å¼"""
        try:
            if keywords is None:
                return []
            elif isinstance(keywords, str):
                # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æä¸ºJSON
                try:
                    import json
                    # å¤„ç†å¯èƒ½çš„è½¬ä¹‰å­—ç¬¦
                    cleaned_keywords = keywords.strip()
                    if cleaned_keywords.startswith('"') and cleaned_keywords.endswith('"'):
                        # å¦‚æœæ˜¯åŒå¼•å·åŒ…å›´çš„å­—ç¬¦ä¸²ï¼Œå…ˆå»æ‰å¼•å·
                        cleaned_keywords = cleaned_keywords[1:-1]
                    
                    parsed = json.loads(cleaned_keywords)
                    if isinstance(parsed, list):
                        return [str(kw) for kw in parsed if kw is not None]
                    else:
                        return [cleaned_keywords]  # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›åŸå­—ç¬¦ä¸²ä½œä¸ºå•ä¸ªå…ƒç´ 
                except (json.JSONDecodeError, TypeError) as e:
                    print(f"Failed to parse keywords JSON: {e}, keywords: {keywords}")
                    return [keywords]  # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›åŸå­—ç¬¦ä¸²ä½œä¸ºå•ä¸ªå…ƒç´ 
            elif isinstance(keywords, list):
                # ç¡®ä¿åˆ—è¡¨ä¸­çš„å…ƒç´ éƒ½æ˜¯å­—ç¬¦ä¸²
                return [str(kw) for kw in keywords if kw is not None]
            else:
                # å…¶ä»–ç±»å‹ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
                return [str(keywords)]
        except Exception as e:
            print(f"Error processing keywords: {e}, keywords: {keywords}")
            return []

    # ç”¨æˆ·ä¿å­˜æ–‡ç« ç›¸å…³æ–¹æ³•
    def save_article_for_user(self, user_id: UUID, news_id: UUID) -> bool:
        """ä¸ºç”¨æˆ·ä¿å­˜æ–‡ç« """
        try:
            existing = self.db.query(SavedArticle).filter(
                SavedArticle.user_id == user_id,
                SavedArticle.news_id == news_id
            ).first()
            if existing:
                return True
            saved_article = SavedArticle(user_id=user_id, news_id=news_id)
            self.db.add(saved_article)
            self.db.commit()
            print(f"âœ… Saved article {news_id} for user {user_id}")
            return True
        except Exception as e:
            print(f"âŒ Error saving article for user: {e}")
            self.db.rollback()
            return False

    def remove_article_from_user(self, user_id: UUID, news_id: UUID) -> bool:
        """ä»ç”¨æˆ·æ”¶è—ä¸­ç§»é™¤æ–‡ç« """
        try:
            saved_article = self.db.query(SavedArticle).filter(
                SavedArticle.user_id == user_id,
                SavedArticle.news_id == news_id
            ).first()
            if saved_article:
                self.db.delete(saved_article)
                self.db.commit()
                print(f"âœ… Removed article {news_id} from user {user_id}")
                return True
            else:
                return True
        except Exception as e:
            print(f"âŒ Error removing article from user: {e}")
            self.db.rollback()
            return False

    def get_saved_articles_for_user(self, user_id: UUID) -> list:
        """è·å–ç”¨æˆ·ä¿å­˜çš„æ–‡ç« åˆ—è¡¨"""
        try:
            saved_articles = self.db.query(SavedArticle).filter(
                SavedArticle.user_id == user_id
            ).all()
            articles = []
            for saved in saved_articles:
                article = self.db.query(News).filter(News.id == saved.news_id).first()
                if article:
                    # ç»„è£…å‰ç«¯éœ€è¦çš„å­—æ®µ
                    articles.append({
                        "id": str(article.id),
                        "title": article.title,
                        "content": article.content,
                        "summary": article.summary,
                        "link": article.link,
                        "date": article.date.isoformat() if article.date else None,
                        "source": article.source,
                        "created_at": article.created_at.isoformat() if article.created_at else None,
                        "published_at": article.published_at.isoformat() if article.published_at else None,
                        "summary_ai": article.summary_ai,
                        "headline_count": article.headline_count,
                        "keywords": article.keywords,
                        "score": article.score
                    })
            print(f"âœ… Retrieved {len(articles)} saved articles for user {user_id}")
            return articles
        except Exception as e:
            print(f"âŒ Error getting saved articles for user: {e}")
            return []

    def is_article_saved_by_user(self, user_id: UUID, news_id: UUID) -> bool:
        """æ£€æŸ¥æ–‡ç« æ˜¯å¦å·²è¢«ç”¨æˆ·ä¿å­˜"""
        try:
            saved_article = self.db.query(SavedArticle).filter(
                SavedArticle.user_id == user_id,
                SavedArticle.news_id == news_id
            ).first()
            return saved_article is not None
        except Exception as e:
            print(f"âŒ Error checking if article is saved by user: {e}")
            return False

    def save_user(self, user_id: str, email: str, name: str) -> bool:
        """ä¿å­˜ç”¨æˆ·ä¿¡æ¯åˆ°æ•°æ®åº“"""
        try:
            # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å·²å­˜åœ¨
            result = self.db.execute(
                text("SELECT id FROM users WHERE id = :user_id"),
                {"user_id": user_id}
            )
            existing_user = result.fetchone()
            
            if existing_user:
                # ç”¨æˆ·å·²å­˜åœ¨ï¼Œæ›´æ–°ä¿¡æ¯
                self.db.execute(
                    text("""
                        UPDATE users 
                        SET email = :email, name = :name 
                        WHERE id = :user_id
                    """),
                    {"user_id": user_id, "email": email, "name": name}
                )
            else:
                # åˆ›å»ºæ–°ç”¨æˆ·
                self.db.execute(
                    text("""
                        INSERT INTO users (id, email, name, created_at) 
                        VALUES (:user_id, :email, :name, NOW())
                    """),
                    {"user_id": user_id, "email": email, "name": name}
                )
            
            self.db.commit()
            print(f"âœ… Saved user {user_id} to database")
            return True
            
        except Exception as e:
            print(f"âŒ Error saving user: {e}")
            self.db.rollback()
            return False

    def _normalize_title(self, title: str) -> str:
        """æ ‡å‡†åŒ–æ ‡é¢˜ç”¨äºå»é‡æ¯”è¾ƒ"""
        # è½¬æ¢ä¸ºå°å†™
        normalized = title.lower()
        # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
        normalized = re.sub(r'\s+', ' ', normalized)
        # ç§»é™¤å¸¸è§çš„æ ‡ç‚¹ç¬¦å·
        normalized = re.sub(r'[^\w\s]', '', normalized)
        # ç§»é™¤é¦–å°¾ç©ºç™½
        normalized = normalized.strip()
        return normalized

    def _is_duplicate_title(self, new_title: str) -> bool:
        """æ£€æŸ¥æ ‡é¢˜æ˜¯å¦é‡å¤ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰"""
        try:
            # åªæ£€æŸ¥å®Œå…¨ç›¸åŒçš„æ ‡é¢˜
            existing = self.db.query(News).filter(News.title == new_title).first()
            return existing is not None
        except Exception as e:
            print(f"Error checking duplicate title: {e}")
            return False 
from sqlalchemy.orm import Session
from sqlalchemy import desc, asc
from app.models import News, Vote, SavedArticle
from app.scoring import calculate_news_score, extract_keywords_from_text, build_existing_keyword_map
from sqlalchemy.exc import NoResultFound
from sqlalchemy import func
from datetime import datetime
from typing import List, Dict, Any
from dateutil import parser as dateparser
from dateutil import tz
from app import redis_client
import json

class PostgresService:
    def __init__(self, db: Session):
        self.db = db

    # è·å–æ–°é—»
    def get_news(self, offset=0, limit=20, sort_by="smart", source_filter=None) -> List[Dict]:
        """è·å–æ–°é—»ï¼Œæ”¯æŒæ™ºèƒ½æ’åºï¼Œä»…ç¼“å­˜é¦–é¡µæ•°æ®ï¼ˆoffset=0ï¼‰"""
        try:
            use_cache = (offset == 0)
            cache_key = f"news:{sort_by}:{offset}:{limit}:{source_filter or 'all'}"
            if use_cache:
                cached = redis_client.get(cache_key)
                if cached:
                    return json.loads(cached)
            
            print(f"ğŸ” DEBUG: Querying news with offset={offset}, limit={limit}, sort_by={sort_by}")
            
            query = self.db.query(News)
            
            # åº”ç”¨æ¥æºè¿‡æ»¤
            if source_filter:
                query = query.filter(News.source.ilike(f"%{source_filter}%"))
            
            # åº”ç”¨æ’åº
            if sort_by == "smart":
                # æ™ºèƒ½æ’åºï¼šæŒ‰ç»¼åˆè¯„åˆ†é™åº
                query = query.order_by(desc(News.score))
            elif sort_by == "time":
                # æ—¶é—´æ’åºï¼šæŒ‰å‘å¸ƒæ—¶é—´é™åº
                query = query.order_by(desc(News.published_at))
            elif sort_by == "headlines":
                # ç‚¹èµæ•°æ’åºï¼šæŒ‰ç‚¹èµæ•°é™åº
                query = query.order_by(desc(News.headline_count))
            else:
                # é»˜è®¤ä½¿ç”¨æ™ºèƒ½æ’åº
                query = query.order_by(desc(News.score))
            
            # åº”ç”¨åˆ†é¡µ
            news_items = query.offset(offset).limit(limit).all()
            
            print(f"ğŸ” DEBUG: Found {len(news_items)} news items in database")
            
            # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
            results = []
            for item in news_items:
                try:
                    # ç¡®ä¿æ—¥æœŸæ ¼å¼æ­£ç¡®
                    date_str = None
                    published_at = item.published_at
                    if published_at:
                        try:
                            # ç¡®ä¿æ˜¯UTCæ—¶é—´å¹¶æ ¼å¼åŒ–ä¸ºISOå­—ç¬¦ä¸²
                            if published_at.tzinfo is None:
                                # å¦‚æœæ²¡æœ‰æ—¶åŒºä¿¡æ¯ï¼Œå‡è®¾æ˜¯UTC
                                date_str = published_at.isoformat() + 'Z'
                            else:
                                # å¦‚æœæœ‰æ—¶åŒºä¿¡æ¯ï¼Œè½¬æ¢ä¸ºUTC
                                from datetime import timezone
                                utc_date = published_at.astimezone(timezone.utc)
                                date_str = utc_date.isoformat()
                        except Exception as e:
                            print(f"Error formatting date: {e}")
                            date_str = datetime.utcnow().isoformat() + 'Z'
                    else:
                        date_str = datetime.utcnow().isoformat() + 'Z'
                    
                    result_item = {
                        "id": str(item.id),  # Convert UUID to string
                        "title": item.title,
                        "content": item.content,
                        "link": item.link,
                        "date": date_str,
                        "source": item.source,
                        "vote_count": self.get_vote_count(item.title),
                        "score": float(item.score) if item.score is not None else 0.0,  # Ensure float
                        "keywords": self._ensure_keywords_array(item.keywords)
                    }
                    results.append(result_item)
                    print(f"ğŸ” DEBUG: Added item: {item.title[:50]}...")
                except Exception as e:
                    print(f"âŒ Error processing news item: {e}")
                    continue
            
            print(f"ğŸ” DEBUG: Returning {len(results)} processed items")
            
            if use_cache:
                try:
                    redis_client.setex(cache_key, 600, json.dumps(results, ensure_ascii=False))
                except Exception as e:
                    print(f"âš ï¸ Cache save failed: {e}")
            
            return results
        except Exception as e:
            print(f"âŒ Error getting news: {e}")
            import traceback
            traceback.print_exc()
            return []

    # ä¿å­˜æ–°é—»
    def save_news(self, news_items: List[Dict]) -> bool:
        """ä¿å­˜æ–°é—»åˆ°æ•°æ®åº“ï¼ŒåŒ…å«æ™ºèƒ½è¯„åˆ†"""
        try:
            print(f"ğŸ” DEBUG: Saving {len(news_items)} news items to database")
            
            # è·å–ç°æœ‰æ–°é—»çš„å…³é”®è¯æ˜ å°„
            existing_news = self.get_news(0, 1000, "time")
            existing_keyword_map = build_existing_keyword_map(existing_news)
            
            saved_count = 0
            for item in news_items:
                try:
                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                    existing = self.db.query(News).filter(News.title == item["title"]).first()
                    if existing:
                        print(f"ğŸ” DEBUG: Skipping existing article: {item['title'][:50]}...")
                        continue
                    
                    # æå–å…³é”®è¯
                    keywords = extract_keywords_from_text(item["title"] + " " + item["content"])
                    
                    # æ ‡å‡†åŒ–æ—¥æœŸå¤„ç†
                    raw_date = item.get("date", "")
                    try:
                        if isinstance(raw_date, str):
                            # è§£æRSSæ—¥æœŸå­—ç¬¦ä¸²å¹¶è½¬æ¢ä¸ºUTCæ—¶é—´
                            parsed_date = dateparser.parse(raw_date)
                            if parsed_date.tzinfo:
                                # å¦‚æœæœ‰æ—¶åŒºä¿¡æ¯ï¼Œè½¬æ¢ä¸ºUTC
                                utc_date = parsed_date.astimezone(tz.tzutc())
                                normalized_date = utc_date.replace(tzinfo=None)
                            else:
                                # å¦‚æœæ²¡æœ‰æ—¶åŒºä¿¡æ¯ï¼Œå‡è®¾æ˜¯UTC
                                normalized_date = parsed_date
                        else:
                            normalized_date = raw_date
                    except Exception as e:
                        print(f"Error parsing date '{raw_date}': {e}")
                        normalized_date = datetime.utcnow()
                    
                    # åˆ›å»ºAIæ‘˜è¦ç»“æ„
                    summary_ai = {
                        "brief": "",
                        "detailed": "",
                        "structure_score": 3.0  # é»˜è®¤è¯„åˆ†
                    }
                    
                    # è®¡ç®—ç»¼åˆè¯„åˆ†
                    score = calculate_news_score(
                        published_at=normalized_date,
                        summary_ai=summary_ai,
                        source=item.get("source", ""),
                        keywords=keywords,
                        headline_count=0,  # æ–°æ–°é—»åˆå§‹ç‚¹èµæ•°ä¸º0
                        existing_keyword_map=existing_keyword_map
                    )
                    
                    # åˆ›å»ºæ–°é—»å¯¹è±¡
                    news = News(
                        title=item["title"],
                        content=item["content"],
                        summary=item.get("summary", ""),
                        link=item["link"],
                        date=normalized_date,
                        source=item.get("source", ""),
                        published_at=normalized_date,
                        summary_ai=summary_ai,
                        headline_count=0,
                        keywords=keywords,
                        score=score
                    )
                    
                    self.db.add(news)
                    saved_count += 1
                    print(f"ğŸ” DEBUG: Added article: {item['title'][:50]}...")
                    
                except Exception as e:
                    print(f"âŒ Error saving individual article: {e}")
                    continue
            
            self.db.commit()
            print(f"ğŸ” DEBUG: Successfully saved {saved_count} new articles to database")
            return True
        except Exception as e:
            print(f"âŒ Error saving news: {e}")
            import traceback
            traceback.print_exc()
            self.db.rollback()
            return False

    # è·å–æŠ•ç¥¨æ•°
    def get_vote_count(self, title: str) -> int:
        """è·å–æŠ•ç¥¨æ•°"""
        try:
            vote = self.db.query(Vote).filter(Vote.title == title).first()
            return int(getattr(vote, "count", 0)) if vote else 0
        except Exception as e:
            print(f"Error getting vote count: {e}")
            return 0

    # æ›´æ–°æŠ•ç¥¨
    def update_vote(self, title: str, delta: int) -> int:
        """æ›´æ–°æŠ•ç¥¨æ•°"""
        try:
            vote = self.db.query(Vote).filter(Vote.title == title).first()
            if not vote:
                vote = Vote(title=title, count=delta)
                self.db.add(vote)
            else:
                current_count = int(getattr(vote, "count", 0))
                new_count = max(0, current_count + delta)
                setattr(vote, "count", new_count)
            
            # åŒæ—¶æ›´æ–°æ–°é—»çš„headline_count
            news = self.db.query(News).filter(News.title == title).first()
            if news:
                news.headline_count = int(getattr(vote, "count", 0))
                # é‡æ–°è®¡ç®—è¯„åˆ†
                self._recalculate_news_score(news)
            
            self.db.commit()
            return int(getattr(vote, "count", 0))
        except Exception as e:
            print(f"Error updating vote: {e}")
            self.db.rollback()
            return 0

    def _recalculate_news_score(self, news: News):
        """é‡æ–°è®¡ç®—æ–°é—»è¯„åˆ†"""
        try:
            # è·å–ç°æœ‰æ–°é—»çš„å…³é”®è¯æ˜ å°„
            existing_news = self.get_news(0, 1000, "time")
            existing_keyword_map = build_existing_keyword_map(existing_news)
            
            # é‡æ–°è®¡ç®—è¯„åˆ†
            published_at = news.published_at or datetime.utcnow()
            summary_ai = news.summary_ai or {}
            keywords = news.keywords or []
            headline_count = news.headline_count or 0
            
            score = calculate_news_score(
                published_at=published_at,
                summary_ai=summary_ai,
                source=news.source,
                keywords=keywords,
                headline_count=headline_count,
                existing_keyword_map=existing_keyword_map
            )
            
            news.score = score
        except Exception as e:
            print(f"Error recalculating score: {e}")

    def update_ai_summary(self, title: str, brief_summary: str, detailed_summary: str, structure_score: float = 3.0):
        """æ›´æ–°AIæ‘˜è¦å’Œç»“æ„è¯„åˆ†"""
        try:
            news = self.db.query(News).filter(News.title == title).first()
            if news:
                news.summary_ai = {
                    "brief": brief_summary,
                    "detailed": detailed_summary,
                    "structure_score": structure_score
                }
                # é‡æ–°è®¡ç®—è¯„åˆ†
                self._recalculate_news_score(news)
                self.db.commit()
        except Exception as e:
            print(f"Error updating AI summary: {e}")
            self.db.rollback()

    def get_article_by_title(self, title: str) -> Dict:
        """æ ¹æ®æ ‡é¢˜è·å–æ–‡ç« ï¼Œå¸¦ç¼“å­˜"""
        try:
            # æ„é€ ç¼“å­˜key
            cache_key = f"article:{title}"
            cached = redis_client.get(cache_key)
            if cached:
                return json.loads(cached)
            
            # ç›´æ¥æŸ¥è¯¢æ•°æ®åº“
            news = self.db.query(News).filter(News.title == title).first()
            
            if news:
                # ç¡®ä¿æ—¥æœŸæ ¼å¼æ­£ç¡®
                date_str = None
                published_at = news.published_at
                if published_at:
                    try:
                        # ç¡®ä¿æ˜¯UTCæ—¶é—´å¹¶æ ¼å¼åŒ–ä¸ºISOå­—ç¬¦ä¸²
                        if published_at.tzinfo is None:
                            # å¦‚æœæ²¡æœ‰æ—¶åŒºä¿¡æ¯ï¼Œå‡è®¾æ˜¯UTC
                            date_str = published_at.isoformat() + 'Z'
                        else:
                            # å¦‚æœæœ‰æ—¶åŒºä¿¡æ¯ï¼Œè½¬æ¢ä¸ºUTC
                            from datetime import timezone
                            utc_date = published_at.astimezone(timezone.utc)
                            date_str = utc_date.isoformat()
                    except Exception as e:
                        print(f"Error formatting date: {e}")
                        date_str = datetime.utcnow().isoformat() + 'Z'
                else:
                    date_str = datetime.utcnow().isoformat() + 'Z'
                
                result = {
                    "id": str(news.id),  # Convert UUID to string
                    "title": news.title,
                    "content": news.content,  # Frontend expects 'content'
                    "link": news.link,
                    "date": date_str,  # Frontend expects 'date'
                    "source": news.source,
                    "vote_count": self.get_vote_count(news.title),
                    "score": float(news.score) if news.score is not None else 0.0,
                    "keywords": self._ensure_keywords_array(news.keywords)
                }
                
                # è®¾ç½®ç¼“å­˜ï¼Œ600ç§’
                redis_client.setex(cache_key, 600, json.dumps(result, ensure_ascii=False))
                return result
            
            # æ²¡æ‰¾åˆ°æ–‡ç« 
            result = {"error": "Article not found"}
            redis_client.setex(cache_key, 600, json.dumps(result, ensure_ascii=False))
            return result
        except Exception as e:
            print(f"Error getting article by title: {e}")
            return {"error": "Article not found"}

    def _ensure_keywords_array(self, keywords: Any) -> List[str]:
        """ç¡®ä¿å…³é”®è¯æ˜¯æ•°ç»„ï¼Œå¤„ç†å„ç§å¯èƒ½çš„æ ¼å¼"""
        try:
            if keywords is None:
                return []
            elif isinstance(keywords, str):
                # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è§£æä¸ºJSON
                try:
                    import json
                    # å¤„ç†å¯èƒ½çš„è½¬ä¹‰å­—ç¬¦
                    cleaned_keywords = keywords.strip()
                    if cleaned_keywords.startswith('"') and cleaned_keywords.endswith('"'):
                        # å¦‚æœæ˜¯åŒå¼•å·åŒ…å›´çš„å­—ç¬¦ä¸²ï¼Œå…ˆå»æ‰å¼•å·
                        cleaned_keywords = cleaned_keywords[1:-1]
                    
                    parsed = json.loads(cleaned_keywords)
                    if isinstance(parsed, list):
                        return [str(kw) for kw in parsed if kw is not None]
                    else:
                        return [cleaned_keywords]  # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›åŸå­—ç¬¦ä¸²ä½œä¸ºå•ä¸ªå…ƒç´ 
                except (json.JSONDecodeError, TypeError) as e:
                    print(f"Failed to parse keywords JSON: {e}, keywords: {keywords}")
                    return [keywords]  # å¦‚æœè§£æå¤±è´¥ï¼Œè¿”å›åŸå­—ç¬¦ä¸²ä½œä¸ºå•ä¸ªå…ƒç´ 
            elif isinstance(keywords, list):
                # ç¡®ä¿åˆ—è¡¨ä¸­çš„å…ƒç´ éƒ½æ˜¯å­—ç¬¦ä¸²
                return [str(kw) for kw in keywords if kw is not None]
            else:
                # å…¶ä»–ç±»å‹ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
                return [str(keywords)]
        except Exception as e:
            print(f"Error processing keywords: {e}, keywords: {keywords}")
            return []

    # ç”¨æˆ·ä¿å­˜æ–‡ç« ç›¸å…³æ–¹æ³•
    def save_article_for_user(self, user_id: str, news_id: str) -> bool:
        """ä¸ºç”¨æˆ·ä¿å­˜æ–‡ç« """
        try:
            # æ£€æŸ¥æ˜¯å¦å·²ç»ä¿å­˜
            existing = self.db.query(SavedArticle).filter(
                SavedArticle.user_id == user_id,
                SavedArticle.news_id == news_id
            ).first()
            
            if existing:
                return True  # å·²ç»ä¿å­˜è¿‡äº†
            
            # åˆ›å»ºæ–°çš„ä¿å­˜è®°å½•
            saved_article = SavedArticle(user_id=user_id, news_id=news_id)
            self.db.add(saved_article)
            self.db.commit()
            print(f"âœ… Saved article {news_id} for user {user_id}")
            return True
        except Exception as e:
            print(f"âŒ Error saving article for user: {e}")
            self.db.rollback()
            return False

    def remove_article_from_user(self, user_id: str, news_id: str) -> bool:
        """ä»ç”¨æˆ·æ”¶è—ä¸­ç§»é™¤æ–‡ç« """
        try:
            saved_article = self.db.query(SavedArticle).filter(
                SavedArticle.user_id == user_id,
                SavedArticle.news_id == news_id
            ).first()
            
            if saved_article:
                self.db.delete(saved_article)
                self.db.commit()
                print(f"âœ… Removed article {news_id} from user {user_id}")
                return True
            else:
                return True  # æœ¬æ¥å°±æ²¡æœ‰ä¿å­˜ï¼Œä¹Ÿç®—æˆåŠŸ
        except Exception as e:
            print(f"âŒ Error removing article from user: {e}")
            self.db.rollback()
            return False

    def get_saved_articles_for_user(self, user_id: str) -> List[Dict]:
        """è·å–ç”¨æˆ·ä¿å­˜çš„æ–‡ç« åˆ—è¡¨"""
        try:
            saved_articles = self.db.query(SavedArticle).filter(
                SavedArticle.user_id == user_id
            ).all()
            
            articles = []
            for saved in saved_articles:
                # è·å–æ–‡ç« è¯¦æƒ…
                article = self.get_article_by_title(saved.news_id)
                if "error" not in article:
                    articles.append(article)
            
            print(f"âœ… Retrieved {len(articles)} saved articles for user {user_id}")
            return articles
        except Exception as e:
            print(f"âŒ Error getting saved articles for user: {e}")
            return []

    def is_article_saved_by_user(self, user_id: str, news_id: str) -> bool:
        """æ£€æŸ¥æ–‡ç« æ˜¯å¦å·²è¢«ç”¨æˆ·ä¿å­˜"""
        try:
            saved_article = self.db.query(SavedArticle).filter(
                SavedArticle.user_id == user_id,
                SavedArticle.news_id == news_id
            ).first()
            
            return saved_article is not None
        except Exception as e:
            print(f"âŒ Error checking if article is saved by user: {e}")
            return False 
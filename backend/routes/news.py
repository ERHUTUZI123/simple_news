from fastapi import APIRouter, Depends, Query, Body, HTTPException, Header, Request
from sqlalchemy.orm import Session
from app.news.postgres_service import PostgresService
from app.db import SessionLocal
from news.fetch_news import get_tech_news
from news.summarize import generate_both_summaries, summarize_news
from urllib.parse import urlparse
import os
from openai import OpenAI
from dotenv import load_dotenv
import time
import random
from typing import Optional
from datetime import datetime, timedelta
from app.models import SavedArticle, User, News
from sqlalchemy.dialects.postgresql import UUID
from uuid import UUID

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

router = APIRouter()

# é€Ÿç‡é™åˆ¶é…ç½®
RATE_LIMIT_DELAY = 2.0  # åŸºç¡€å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰
MAX_RETRIES = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°

def handle_openai_rate_limit(func):
    """è£…é¥°å™¨ï¼šå¤„ç†OpenAIé€Ÿç‡é™åˆ¶"""
    def wrapper(*args, **kwargs):
        for attempt in range(MAX_RETRIES):
            try:
                return func(*args, **kwargs)
            except Exception as e:
                error_str = str(e)
                if "rate_limit" in error_str.lower() or "429" in error_str:
                    if attempt < MAX_RETRIES - 1:
                        # è®¡ç®—å»¶è¿Ÿæ—¶é—´ï¼šåŸºç¡€å»¶è¿Ÿ + éšæœºæŠ–åŠ¨
                        delay = RATE_LIMIT_DELAY + random.uniform(0, 1)
                        print(f"âš ï¸ [RATE_LIMIT] Attempt {attempt + 1} failed, retrying in {delay:.2f}s...")
                        time.sleep(delay)
                        continue
                    else:
                        print(f"âŒ [RATE_LIMIT] Max retries reached, returning default value")
                        return None
                else:
                    # éé€Ÿç‡é™åˆ¶é”™è¯¯ï¼Œç›´æ¥æŠ›å‡º
                    raise e
        return None
    return wrapper

def get_pg_service():
    db = SessionLocal()
    try:
        yield PostgresService(db)
    finally:
        db.close()

def get_first_n_words(text: str, n: int) -> str:
    """è·å–æ–‡æœ¬çš„å‰nä¸ªå•è¯"""
    if not text:
        return ""
    words = text.split()
    return " ".join(words[:n])

@router.get("/news/today")
def get_today_news(
    pg_service: PostgresService = Depends(get_pg_service),
    offset: int = Query(0, ge=0),
    limit: int = Query(20, ge=1, le=100),
    sort_by: str = Query("smart"),  # é»˜è®¤ä½¿ç”¨æ™ºèƒ½æ’åº
    source_filter: str = Query(None)
):
    """è·å–ä»Šæ—¥æ–°é—»ï¼Œæ”¯æŒæ™ºèƒ½æ’åº"""
    # è·å– Postgres çš„æ–°é—»
    news_items = pg_service.get_news(offset, limit, sort_by, source_filter)
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ·æ–°æ–°é—»
    should_refresh = False
    if not news_items:
        should_refresh = True
    else:
        # æ£€æŸ¥æœ€æ–°æ–°é—»çš„å¹´é¾„ï¼Œå¦‚æœè¶…è¿‡2å°æ—¶å°±åˆ·æ–°
        latest_news = pg_service.get_news(0, 1, "time")
        if latest_news and len(latest_news) > 0:
            latest_date_str = latest_news[0].get('published_at')
            if latest_date_str:
                try:
                    latest_date = datetime.fromisoformat(latest_date_str.replace('Z', '+00:00'))
                    now = datetime.utcnow()
                    if (now - latest_date) > timedelta(hours=2):
                        should_refresh = True
                except:
                    should_refresh = True
    
    if should_refresh:
        # æŠ“å– RSS å¹¶å­˜å…¥
        raw = get_tech_news(force_refresh=True)
        pg_service.save_news(raw)
        news_items = pg_service.get_news(offset, limit, sort_by, source_filter)
    
    return news_items

@router.post("/news/vote")
def vote_news(
    title: str = Query(...),
    delta: int = Query(1),
    pg_service: PostgresService = Depends(get_pg_service)
):
    """æŠ•ç¥¨æ¥å£"""
    new_count = pg_service.update_vote(title, delta)
    return {"count": new_count}

@router.get("/news/vote")
def get_vote(
    title: str = Query(...),
    pg_service: PostgresService = Depends(get_pg_service)
):
    """è·å–æŠ•ç¥¨æ•°"""
    count = pg_service.get_vote_count(title)
    return {"count": count}

@router.post("/news/summary")
def news_summary(data: dict = Body(...)):
    """Generate news summary"""
    content = data.get("content", "")
    summary_type = data.get("type", "detailed")  # Default to detailed
    
    if summary_type == "both":
        # Generate both types of summaries
        result = generate_both_summaries(content)
        return result
    else:
        # Generate single type summary
        result = summarize_news(content, summary_type)
        return {"summary": result["summary"], "structure_score": result["structure_score"]}

@router.get("/news/article")
def get_article_by_title(
    title: str = Query(...),
    pg_service: PostgresService = Depends(get_pg_service)
):
    """æ ¹æ®æ ‡é¢˜è·å–æ–‡ç« """
    return pg_service.get_article_by_title(title)

@router.get("/news/article/{article_id}")
def get_article_by_id(article_id: str):
    """æ ¹æ®IDè·å–æ–‡ç« ï¼ˆå…¼å®¹æ€§æ¥å£ï¼‰"""
    # è¿™é‡Œå¯ä»¥æ ¹æ®éœ€è¦å®ç°å…·ä½“çš„é€»è¾‘
    return {"error": "Article not found"}

@router.post("/news/refresh")
def refresh_news(
    pg_service: PostgresService = Depends(get_pg_service)
):
    """æ‰‹åŠ¨åˆ·æ–°æ–°é—»"""
    try:
        raw = get_tech_news(force_refresh=True)
        success = pg_service.save_news(raw)
        if success:
            return {"message": "News refreshed successfully", "count": len(raw)}
        else:
            raise HTTPException(status_code=500, detail="Failed to save news")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to refresh news: {str(e)}")

@router.get("/news/sources")
def get_news_sources(
    pg_service: PostgresService = Depends(get_pg_service)
):
    """è·å–æ‰€æœ‰æ–°é—»æ¥æº"""
    try:
        # è¿”å›æ‰€æœ‰æ”¯æŒçš„æ–°é—»æ¥æº
        sources = [
            # ç¾å›½ä¸»æµåª’ä½“
            "The New York Times", "The Washington Post", "Los Angeles Times", 
            "NBC News", "CBS News", "ABC News", "Fox News", "CNBC", "Axios",
            # å›½é™…æ–°é—»æœºæ„
            "Reuters", "Associated Press", "Bloomberg",
            # è‹±å›½åª’ä½“
            "BBC News", "The Guardian", "The Telegraph", 
            "Financial Times", "Sky News", "The Independent",
            # æ¬§æ´²åª’ä½“
            "Euronews", "Deutsche Welle",
            # ä¸­ä¸œåª’ä½“
            "Al Jazeera",
        ]
        return {"sources": sources}
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to get sources: {str(e)}")

@router.get("/news/sort-options")
def get_sort_options():
    """è·å–æ’åºé€‰é¡¹"""
    return {
        "options": [
            {"value": "smart", "label": "Smart Sort (Recommended)"},
            {"value": "time", "label": "Latest First"},
            {"value": "headlines", "label": "Most Popular"}
        ]
    }

@router.post("/api/save")
async def save_article(request: Request, pg_service: PostgresService = Depends(get_pg_service)):
    """ä¿å­˜æ–‡ç« åˆ°ç”¨æˆ·æ”¶è—"""
    try:
        data = await request.json()
        user_id = UUID(data.get("userId"))
        news_id = UUID(data.get("newsId"))
        
        if not user_id or not news_id:
            raise HTTPException(status_code=400, detail="Missing userId or newsId")
        
        # æ£€æŸ¥æ–‡ç« æ˜¯å¦å­˜åœ¨
        article = pg_service.get_article_by_title(news_id)
        if "error" in article:
            raise HTTPException(status_code=404, detail="Article not found")
        
        # ä¿å­˜åˆ°æ•°æ®åº“
        success = pg_service.save_article_for_user(user_id, news_id)
        if success:
            return {"success": True, "message": "Article saved successfully"}
        else:
            raise HTTPException(status_code=500, detail="Failed to save article")
            
    except HTTPException:
        raise
    except Exception as e:
        print(f"Error saving article: {e}")
        raise HTTPException(status_code=500, detail="Internal server error")

@router.delete("/api/save")
async def unsave_article(request: Request, pg_service: PostgresService = Depends(get_pg_service)):
    """ä»ç”¨æˆ·æ”¶è—ä¸­ç§»é™¤æ–‡ç« """
    try:
        data = await request.json()
        user_id = UUID(data.get("userId"))
        news_id = UUID(data.get("newsId"))
        
        if not user_id or not news_id:
            raise HTTPException(status_code=400, detail="Missing userId or newsId")
        
        # ä»æ•°æ®åº“ä¸­ç§»é™¤
        success = pg_service.remove_article_from_user(user_id, news_id)
        if success:
            return {"success": True, "message": "Article removed from saved"}
        else:
            raise HTTPException(status_code=500, detail="Failed to remove article")
            
    except HTTPException:
        raise
    except Exception as e:
        print(f"Error removing article: {e}")
        raise HTTPException(status_code=500, detail="Internal server error")

@router.get("/api/saved")
async def get_saved_articles(
    user_id: str = Query(...),
    pg_service: PostgresService = Depends(get_pg_service)
):
    """è·å–ç”¨æˆ·ä¿å­˜çš„æ–‡ç« åˆ—è¡¨"""
    try:
        user_id = UUID(user_id)
        saved_articles = pg_service.get_saved_articles_for_user(user_id)
        return {"articles": saved_articles}
    except Exception as e:
        print(f"Error getting saved articles: {e}")
        raise HTTPException(status_code=500, detail="Internal server error")

@router.get("/api/saved/check")
async def check_article_saved(
    user_id: str = Query(...),
    news_id: str = Query(...),
    pg_service: PostgresService = Depends(get_pg_service)
):
    """æ£€æŸ¥æ–‡ç« æ˜¯å¦å·²è¢«ç”¨æˆ·ä¿å­˜"""
    try:
        user_id = UUID(user_id)
        news_id = UUID(news_id)
        is_saved = pg_service.is_article_saved_by_user(user_id, news_id)
        return {"saved": is_saved}
    except Exception as e:
        print(f"Error checking saved status: {e}")
        raise HTTPException(status_code=500, detail="Internal server error")

@router.post("/api/auth/save-user")
async def save_user(request: Request, pg_service: PostgresService = Depends(get_pg_service)):
    """ä¿å­˜Googleç”¨æˆ·ä¿¡æ¯åˆ°æ•°æ®åº“"""
    try:
        data = await request.json()
        user_id = data.get("id")
        email = data.get("email")
        name = data.get("name")
        
        if not user_id or not email:
            raise HTTPException(status_code=400, detail="Missing required user information")
        
        # ä¿å­˜ç”¨æˆ·åˆ°æ•°æ®åº“
        success = pg_service.save_user(user_id, email, name)
        if success:
            return {"success": True, "message": "User saved successfully"}
        else:
            raise HTTPException(status_code=500, detail="Failed to save user")
            
    except HTTPException:
        raise
    except Exception as e:
        print(f"Error saving user: {e}")
        raise HTTPException(status_code=500, detail="Internal server error")

@router.post("/news/clean-duplicates")
def clean_duplicate_news(pg_service: PostgresService = Depends(get_pg_service)):
    """æ¸…ç†é‡å¤çš„æ–°é—»æ¡ç›®"""
    try:
        # è·å–æ‰€æœ‰æ–°é—»
        all_news = pg_service.db.query(News).all()
        print(f"ğŸ” Found {len(all_news)} total news articles")
        
        # æŒ‰æ ‡å‡†åŒ–æ ‡é¢˜åˆ†ç»„
        title_groups = {}
        for news in all_news:
            normalized_title = pg_service._normalize_title(news.title)
            if normalized_title not in title_groups:
                title_groups[normalized_title] = []
            title_groups[normalized_title].append(news)
        
        # æ‰¾å‡ºé‡å¤çš„ç»„
        duplicates_removed = 0
        for normalized_title, news_list in title_groups.items():
            if len(news_list) > 1:
                print(f"ğŸ” Found {len(news_list)} duplicates for: {normalized_title[:50]}...")
                
                # ä¿ç•™æœ€æ–°çš„ä¸€ä¸ªï¼Œåˆ é™¤å…¶ä»–çš„
                sorted_news = sorted(news_list, key=lambda x: x.created_at, reverse=True)
                for news_to_delete in sorted_news[1:]:
                    pg_service.db.delete(news_to_delete)
                    duplicates_removed += 1
                    print(f"ğŸ—‘ï¸ Deleted duplicate: {news_to_delete.title[:50]}...")
        
        pg_service.db.commit()
        print(f"âœ… Cleaned up {duplicates_removed} duplicate articles")
        
        return {
            "success": True, 
            "message": f"Cleaned up {duplicates_removed} duplicate articles",
            "duplicates_removed": duplicates_removed
        }
        
    except Exception as e:
        print(f"âŒ Error cleaning duplicates: {e}")
        pg_service.db.rollback()
        raise HTTPException(status_code=500, detail=f"Failed to clean duplicates: {str(e)}")
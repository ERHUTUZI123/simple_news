from fastapi import APIRouter, Depends, Query, Body, HTTPException, Header
from sqlalchemy.orm import Session
from news.fetch_news import get_tech_news
from news.db import SessionLocal
from news.mongo_service import MongoService
from models import Vote, User
from urllib.parse import urlparse
import os
from openai import OpenAI
from dotenv import load_dotenv
from google.oauth2 import id_token
from google.auth.transport import requests as google_requests
import time
import random
from typing import Optional

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

router = APIRouter()

# é€Ÿç‡é™åˆ¶é…ç½®
RATE_LIMIT_DELAY = 2.0  # åŸºç¡€å»¶è¿Ÿæ—¶é—´ï¼ˆç§’ï¼‰
MAX_RETRIES = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°

def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

def get_mongo_service():
    """è·å– MongoDB æœåŠ¡å®ä¾‹"""
    return MongoService()

def get_first_n_words(text: str, n: int) -> str:
    """è·å–æ–‡æœ¬çš„å‰nä¸ªå•è¯"""
    if not text:
        return ""
    words = text.split()
    return " ".join(words[:n])

def get_current_user(
    authorization: str = Header(None),
    mongo_service: MongoService = Depends(get_mongo_service)
):
    if not authorization or not authorization.startswith("Bearer "):
        raise HTTPException(status_code=401, detail="Not authenticated")
    token = authorization.split(" ", 1)[1]
    try:
        idinfo = id_token.verify_oauth2_token(token, google_requests.Request())
        email = idinfo["email"]
        user = mongo_service.get_user(email)
        if not user:
            mongo_service.create_user(email, is_subscribed=False)
            user = mongo_service.get_user(email)
        return user
    except Exception:
        raise HTTPException(status_code=401, detail="Invalid token")

# æ¥æºæƒé‡é…ç½®
SOURCE_WEIGHTS = {
    "Financial Times": 1.0,
    "Wall Street Journal": 1.0,
    "The Economist": 1.0,
    "Reuters": 0.9,
    "Bloomberg": 0.9,
    "BBC": 0.8,
    "CNN": 0.8,
    "The New York Times": 0.8,
    "The Washington Post": 0.8,
    "The Guardian": 0.7,
    "TechCrunch": 0.6,
    "Ars Technica": 0.6,
    "Wired": 0.6,
    "The Verge": 0.5,
    "Engadget": 0.5,
    "Mashable": 0.4,
    "Gizmodo": 0.4,
}

def calculate_comprehensive_score(item, vote_count, ai_score):
    """è®¡ç®—ç»¼åˆè¯„åˆ†"""
    from datetime import datetime, timedelta
    
    # 1. æ—¶é—´å› å­ (0-1, è¶Šæ–°è¶Šé«˜)
    try:
        pub_date = datetime.fromisoformat(item["date"].replace('Z', '+00:00'))
        now = datetime.now(pub_date.tzinfo)
        hours_ago = (now - pub_date).total_seconds() / 3600
        
        if hours_ago <= 12:
            time_factor = 1.0 - (hours_ago / 12) * 0.3  # 12å°æ—¶å†…ï¼Œæœ€é«˜1.0ï¼Œæœ€ä½0.7
        elif hours_ago <= 24:
            time_factor = 0.7 - ((hours_ago - 12) / 12) * 0.3  # 24å°æ—¶å†…ï¼Œ0.7åˆ°0.4
        else:
            time_factor = max(0.1, 0.4 - (hours_ago - 24) / 24 * 0.3)  # è¶…è¿‡24å°æ—¶ï¼Œæœ€ä½0.1
    except:
        time_factor = 0.5  # è§£æå¤±è´¥æ—¶ä½¿ç”¨é»˜è®¤å€¼
    
    # 2. æ¥æºæƒé‡ (0-1)
    source = item.get("source", "")
    source_weight = SOURCE_WEIGHTS.get(source, 0.3)  # é»˜è®¤æƒé‡0.3
    
    # 3. AIè´¨é‡åˆ† (0-1)
    ai_quality = (ai_score or 5) / 10.0  # è½¬æ¢ä¸º0-1
    
    # 4. çƒ­åº¦å› å­ (0-1)
    # åŸºäºæŠ•ç¥¨æ•°ï¼Œä½¿ç”¨å¯¹æ•°å‡½æ•°é¿å…æç«¯å€¼
    popularity_factor = min(1.0, (vote_count + 1) / 10.0)  # 0-1ï¼Œ10ç¥¨ä»¥ä¸Šç®—æ»¡åˆ†
    
    # ç»¼åˆè¯„åˆ†å…¬å¼
    comprehensive_score = (
        time_factor * 0.5 +      # æ—¶é—´æƒé‡50%
        source_weight * 0.2 +    # æ¥æºæƒé‡20%
        ai_quality * 0.2 +       # AIè´¨é‡æƒé‡20%
        popularity_factor * 0.1  # çƒ­åº¦æƒé‡10%
    )
    
    return comprehensive_score

def handle_openai_rate_limit(func):
    """è£…é¥°å™¨ï¼šå¤„ç†OpenAIé€Ÿç‡é™åˆ¶"""
    def wrapper(*args, **kwargs):
        for attempt in range(MAX_RETRIES):
            try:
                return func(*args, **kwargs)
            except Exception as e:
                error_str = str(e)
                if "rate_limit" in error_str.lower() or "429" in error_str:
                    if attempt < MAX_RETRIES - 1:
                        # è®¡ç®—å»¶è¿Ÿæ—¶é—´ï¼šåŸºç¡€å»¶è¿Ÿ + éšæœºæŠ–åŠ¨
                        delay = RATE_LIMIT_DELAY + random.uniform(0, 1)
                        print(f"âš ï¸ [RATE_LIMIT] Attempt {attempt + 1} failed, retrying in {delay:.2f}s...")
                        time.sleep(delay)
                        continue
                    else:
                        print(f"âŒ [RATE_LIMIT] Max retries reached, returning default value")
                        return None
                else:
                    # éé€Ÿç‡é™åˆ¶é”™è¯¯ï¼Œç›´æ¥æŠ›å‡º
                    raise e
        return None
    return wrapper

# ç°åœ¨å†å®šä¹‰ get_today_news è·¯ç”±
@router.get("/news/today")
def get_today_news(
    mongo_service: MongoService = Depends(get_mongo_service),
    offset: int = Query(0, ge=0),
    limit: int = Query(20, ge=1, le=100),
    sort_by: str = Query("smart", regex="^(smart|time|popular|ai_quality|source)$"),
    source_filter: str = Query(None)
):
    # ç®€åŒ–å¤„ç†ï¼šä½¿ç”¨é»˜è®¤é™åˆ¶
    max_limit = 100
    limit = min(limit, max_limit)

    # ä» MongoDB è·å–æ–°é—»
    news_items = mongo_service.get_news(offset, limit, sort_by, source_filter)
    
    # å¦‚æœæ²¡æœ‰ç¼“å­˜çš„æ–°é—»ï¼Œä» RSS è·å–å¹¶å­˜å…¥ MongoDB
    if not news_items:
        raw = get_tech_news(force_refresh=True)
        mongo_service.save_news(raw)  # âœ… ä¿å­˜æŠ“å–ç»“æœåˆ° MongoDB
        news_items = mongo_service.get_news(offset, limit, sort_by, source_filter)
    
    results = []
    
    for item in news_items:
        source = item.get("source") or urlparse(item["link"]).netloc.replace("www.", "")
        
        # åº”ç”¨æ¥æºç­›é€‰
        if source_filter and source_filter.lower() not in source.lower():
            continue
            
        # ä» MongoDB è·å–æŠ•ç¥¨æ•°
        vote_count = mongo_service.get_vote_count(item["title"])

        content = item.get("content") or item.get("summary") or ""
        summary = get_first_n_words(content, 600)
        
        # è·å–AIè¯„åˆ†
        ai_score = score_news(content) if content else 5

        # è®¡ç®—ç»¼åˆè¯„åˆ†
        comprehensive_score = calculate_comprehensive_score(item, vote_count, ai_score)

        results.append({
            "title": item["title"],
            "content": content,
            "summary": summary,
            "link": item["link"],
            "date": item["date"],
            "source": source,
            "vote_count": vote_count,
            "ai_score": ai_score,
            "comprehensive_score": comprehensive_score
        })
    
    # æ ¹æ®æ’åºæ–¹å¼æ’åº
    if sort_by == "smart":
        # æ™ºèƒ½ç»¼åˆæ’åºï¼ˆé»˜è®¤ï¼‰
        results.sort(key=lambda x: x["comprehensive_score"], reverse=True)
    elif sort_by == "time":
        # æœ€æ–°å‘å¸ƒ
        results.sort(key=lambda x: x["date"], reverse=True)
    elif sort_by == "popular":
        # çƒ­é—¨æ”¶è—
        results.sort(key=lambda x: x["vote_count"], reverse=True)
    elif sort_by == "ai_quality":
        # AIè´¨é‡æ’åº
        results.sort(key=lambda x: x["ai_score"], reverse=True)
    
    return results

@router.post("/news/vote")
def vote_news(
    title: str = Query(...),
    delta: int = Query(1),
    mongo_service: MongoService = Depends(get_mongo_service)
):
    """æŠ•ç¥¨æ¥å£"""
    new_count = mongo_service.update_vote(title, delta)
    return {"count": new_count}

@router.get("/news/vote")
def get_vote(title: str = Query(...), mongo_service: MongoService = Depends(get_mongo_service)):
    """è·å–æŠ•ç¥¨æ•°"""
    count = mongo_service.get_vote_count(title)
    return {"count": count}

@router.post("/news/summary")
def news_summary(data: dict = Body(...)):
    """ç”Ÿæˆæ–°é—»æ‘˜è¦"""
    content = data.get("content", "")
    summary = summarize_news(content)
    return {"summary": summary}

@router.get("/news/score")
def news_score(text: str = Query(...)):
    """ç‹¬ç«‹æ‰“åˆ†æ¥å£ï¼Œè¿”å› 1-10 åˆ†"""
    score = score_news(text)
    return {"ai_score": score}

@router.get("/news/article")
def get_article_by_title(title: str = Query(...)):
    """æ ¹æ®æ ‡é¢˜è·å–æ–‡ç« """
    mongo_service = MongoService()
    news_items = mongo_service.get_news(0, 1000)  # è·å–æ‰€æœ‰æ–°é—»
    
    for item in news_items:
        if item["title"] == title:
            return item
    
    return {"error": "Article not found"}

@router.get("/news/article/{article_id}")
def get_article_by_id(article_id: str):
    """æ ¹æ®IDè·å–æ–‡ç« ï¼ˆå…¼å®¹æ€§æ¥å£ï¼‰"""
    # è¿™é‡Œå¯ä»¥æ ¹æ®éœ€è¦å®ç°å…·ä½“çš„é€»è¾‘
    return {"error": "Article not found"}

@handle_openai_rate_limit
def _call_openai_summarize(prompt: str, max_tokens: int) -> Optional[str]:
    """è°ƒç”¨OpenAIç”Ÿæˆæ‘˜è¦"""
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=max_tokens,
            temperature=0.7
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"âŒ [ERROR] OpenAI summarize error: {e}")
        return None

@handle_openai_rate_limit
def _call_openai_score(prompt: str) -> Optional[str]:
    """è°ƒç”¨OpenAIè¯„åˆ†"""
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=10,
            temperature=0.3
        )
        return response.choices[0].message.content
    except Exception as e:
        print(f"âŒ [ERROR] OpenAI score error: {e}")
        return None

def summarize_news(text: str, word_count: int = 70) -> str:
    print(f"ğŸ¤– [DEBUG] summarize_news called with text length: {len(text)}")
    print(f"ğŸ¤– [DEBUG] Text preview: {text[:300]}...")
    
    if not text.strip():
        print("âŒ [ERROR] Empty text passed to summarize_news!")
        return "No content available for summarization"
    
    prompt = (
        "Read the whole article and summarize this news in at least 420 characters "
        "and more than 65 words. Be as detailed as possible. Do not just copy and paste content."
        "Do not mention the source, outlet, or 'the article'. Just summarize the core content.\n\n"
        f"{text}"
    )
    
    try:
        content = _call_openai_summarize(prompt, word_count * 2)
        if content is None:
            print("âŒ [ERROR] OpenAI call failed due to rate limiting")
            return "Summary generation temporarily unavailable due to high demand"
        
        result = content.strip() if content else "generation failed"
        print(f"âœ… [DEBUG] Generated summary: {result[:100]}...")
        return result
    except Exception as e:
        print(f"âŒ [ERROR] OpenAI summarize error: {e}")
        return "generation failed"

def score_news(text: str) -> int:
    """è¯„åˆ†æ–°é—»è´¨é‡ï¼Œè¿”å›1-10åˆ†"""
    if not text.strip():
        return 5
    
    prompt = (
        "Rate the quality and newsworthiness of this news article on a scale of 1-10. "
        "Consider factors like accuracy, relevance, depth, and journalistic quality. "
        "Respond with only the number (1-10).\n\n"
        f"Article: {text[:1000]}..."
    )
    
    try:
        result = _call_openai_score(prompt)
        if result:
            # æå–æ•°å­—
            import re
            numbers = re.findall(r'\d+', result)
            if numbers:
                score = int(numbers[0])
                return max(1, min(10, score))  # ç¡®ä¿åœ¨1-10èŒƒå›´å†…
    except Exception as e:
        print(f"âŒ [ERROR] Score parsing error: {e}")
    
    return 5  # é»˜è®¤åˆ†æ•°
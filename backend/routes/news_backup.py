from fastapi import APIRouter, Depends, Query, Body, HTTPException, Header
from sqlalchemy.orm import Session
from news.fetch_news import get_tech_news
from backend.db import SessionLocal
from models import Vote, User
from urllib.parse import urlparse
import os
from openai import OpenAI
from dotenv import load_dotenv
from google.oauth2 import id_token
from google.auth.transport import requests as google_requests

load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

router = APIRouter()

def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()

def get_first_n_words(text: str, n: int) -> str:
    """è·å–æ–‡æœ¬çš„å‰nä¸ªå•è¯"""
    if not text:
        return ""
    words = text.split()
    return " ".join(words[:n])

def get_current_user(
    authorization: str = Header(None),
    db: Session = Depends(get_db)
):
    if not authorization or not authorization.startswith("Bearer "):
        raise HTTPException(status_code=401, detail="Not authenticated")
    token = authorization.split(" ", 1)[1]
    try:
        idinfo = id_token.verify_oauth2_token(token, google_requests.Request())
        email = idinfo["email"]
        user = db.query(User).filter(User.email == email).first()
        if not user:
            user = User(email=email, is_subscribed=False)
            db.add(user)
            db.commit()
            db.refresh(user)
        return user
    except Exception:
        raise HTTPException(status_code=401, detail="Invalid token")

# æ¥æºæƒé‡é…ç½®
SOURCE_WEIGHTS = {
    "Financial Times": 1.0,
    "Wall Street Journal": 1.0,
    "The Economist": 1.0,
    "Reuters": 0.9,
    "Bloomberg": 0.9,
    "BBC": 0.8,
    "CNN": 0.8,
    "The New York Times": 0.8,
    "The Washington Post": 0.8,
    "The Guardian": 0.7,
    "TechCrunch": 0.6,
    "Ars Technica": 0.6,
    "Wired": 0.6,
    "The Verge": 0.5,
    "Engadget": 0.5,
    "Mashable": 0.4,
    "Gizmodo": 0.4,
}

def calculate_comprehensive_score(item, vote_count, ai_score):
    """è®¡ç®—ç»¼åˆè¯„åˆ†"""
    from datetime import datetime, timedelta
    
    # 1. æ—¶é—´å› å­ (0-1, è¶Šæ–°è¶Šé«˜)
    try:
        pub_date = datetime.fromisoformat(item["date"].replace('Z', '+00:00'))
        now = datetime.now(pub_date.tzinfo)
        hours_ago = (now - pub_date).total_seconds() / 3600
        
        if hours_ago <= 12:
            time_factor = 1.0 - (hours_ago / 12) * 0.3  # 12å°æ—¶å†…ï¼Œæœ€é«˜1.0ï¼Œæœ€ä½0.7
        elif hours_ago <= 24:
            time_factor = 0.7 - ((hours_ago - 12) / 12) * 0.3  # 24å°æ—¶å†…ï¼Œ0.7åˆ°0.4
        else:
            time_factor = max(0.1, 0.4 - (hours_ago - 24) / 24 * 0.3)  # è¶…è¿‡24å°æ—¶ï¼Œæœ€ä½0.1
    except:
        time_factor = 0.5  # è§£æå¤±è´¥æ—¶ä½¿ç”¨é»˜è®¤å€¼
    
    # 2. æ¥æºæƒé‡ (0-1)
    source = item.get("source", "")
    source_weight = SOURCE_WEIGHTS.get(source, 0.3)  # é»˜è®¤æƒé‡0.3
    
    # 3. AIè´¨é‡åˆ† (0-1)
    ai_quality = (ai_score or 5) / 10.0  # è½¬æ¢ä¸º0-1
    
    # 4. çƒ­åº¦å› å­ (0-1)
    # åŸºäºæŠ•ç¥¨æ•°ï¼Œä½¿ç”¨å¯¹æ•°å‡½æ•°é¿å…æç«¯å€¼
    popularity_factor = min(1.0, (vote_count + 1) / 10.0)  # 0-1ï¼Œ10ç¥¨ä»¥ä¸Šç®—æ»¡åˆ†
    
    # ç»¼åˆè¯„åˆ†å…¬å¼
    comprehensive_score = (
        time_factor * 0.5 +      # æ—¶é—´æƒé‡50%
        source_weight * 0.2 +    # æ¥æºæƒé‡20%
        ai_quality * 0.2 +       # AIè´¨é‡æƒé‡20%
        popularity_factor * 0.1  # çƒ­åº¦æƒé‡10%
    )
    
    return comprehensive_score

# ç°åœ¨å†å®šä¹‰ get_today_news è·¯ç”±
@router.get("/news/today")
def get_today_news(
    db: Session = Depends(get_db),
    user: User = None,  # ä¸´æ—¶è®¾ä¸ºå¯é€‰
    offset: int = Query(0, ge=0),
    limit: int = Query(20, ge=1, le=100),
    sort_by: str = Query("smart", regex="^(smart|time|popular|ai_quality|source)$"),
    source_filter: str = Query(None)
):
    # ä¸´æ—¶å¤„ç†ï¼šå¦‚æœæ²¡æœ‰ç”¨æˆ·ï¼Œä½¿ç”¨é»˜è®¤é™åˆ¶
    max_limit = 100 if user and user.is_subscribed else 20
    limit = min(limit, max_limit)

    raw = get_tech_news()
    results = []
    
    for item in raw:
        source = item.get("source") or urlparse(item["link"]).netloc.replace("www.", "")
        
        # åº”ç”¨æ¥æºç­›é€‰
        if source_filter and source_filter.lower() not in source.lower():
            continue
            
        vote = db.query(Vote).filter(Vote.title == item["title"]).first()
        vote_count = vote.count if vote is not None else 0

        content = item.get("content") or item.get("summary") or ""
        summary = get_first_n_words(content, 600)
        
        # è·å–AIè¯„åˆ†
        ai_score = score_news(content) if content else 5

        # è®¡ç®—ç»¼åˆè¯„åˆ†
        comprehensive_score = calculate_comprehensive_score(item, vote_count, ai_score)

        results.append({
            "title": item["title"],
            "content": content,
            "summary": summary,
            "link": item["link"],
            "date": item["date"],
            "source": source,
            "vote_count": vote_count,
            "ai_score": ai_score,
            "comprehensive_score": comprehensive_score
        })
    
    # æ ¹æ®æ’åºæ–¹å¼æ’åº
    if sort_by == "smart":
        # æ™ºèƒ½ç»¼åˆæ’åºï¼ˆé»˜è®¤ï¼‰
        results.sort(key=lambda x: x["comprehensive_score"], reverse=True)
    elif sort_by == "time":
        # æœ€æ–°å‘å¸ƒ
        results.sort(key=lambda x: x["date"], reverse=True)
    elif sort_by == "popular":
        # çƒ­é—¨æ”¶è—
        results.sort(key=lambda x: x["vote_count"], reverse=True)
    elif sort_by == "ai_quality":
        # AIç²¾é€‰
        results.sort(key=lambda x: x["ai_score"], reverse=True)
    elif sort_by == "source":
        # æŒ‰æ¥æºæƒé‡æ’åº
        results.sort(key=lambda x: SOURCE_WEIGHTS.get(x["source"], 0), reverse=True)
    
    return results[offset:offset+limit]

@router.post("/news/vote")
def vote_news(
    title: str = Query(...),
    delta: int = Query(1),
    db: Session = Depends(get_db)
):
    vote = db.query(Vote).filter(Vote.title == title).first()
    if vote is not None:
        vote.count = vote.count + delta
    else:
        vote = Vote(title=title, count=delta)
        db.add(vote)
    db.commit()
    db.refresh(vote)
    return {"count": vote.count}

@router.get("/news/vote")
def get_vote(title: str = Query(...), db: Session = Depends(get_db)):
    vote = db.query(Vote).filter(Vote.title == title).first()
    return {"count": vote.count if vote else 0}

@router.post("/news/summary")
def news_summary(data: dict = Body(...)):
    text = data.get("content", "")
    print(f"ğŸ” [DEBUG] Received content length: {len(text)}")
    print(f"ğŸ” [DEBUG] Content preview: {text[:200]}...")
    print(f"ğŸ” [DEBUG] Content is empty: {not text.strip()}")
    return {"summary": summarize_news(text, 300)}

@router.get("/news/score")
def news_score(text: str = Query(...)):
    # ç‹¬ç«‹æ‰“åˆ†æ¥å£ï¼Œè¿”å› 1-10 åˆ†
    score = score_news(text)
    return {"ai_score": score}

@router.get("/news/article")
def get_article_by_title(title: str = Query(...)):
    """æ ¹æ®æ ‡é¢˜è·å–æ–‡ç« è¯¦æƒ…"""
    raw = get_tech_news()
    for item in raw:
        if item["title"] == title:
            source = item.get("source") or urlparse(item["link"]).netloc.replace("www.", "")
            content = item.get("content") or item.get("summary") or ""
            
            return {
                "id": item.get("id", ""),
                "title": item["title"],
                "content": content,
                "link": item["link"],
                "date": item["date"],
                "source": source
            }
    
    raise HTTPException(status_code=404, detail="Article not found")

@router.get("/news/article/{article_id}")
def get_article_by_id(article_id: str):
    """æ ¹æ®IDè·å–æ–‡ç« è¯¦æƒ…"""
    raw = get_tech_news()
    for item in raw:
        if str(item.get("id", "")) == article_id:
            source = item.get("source") or urlparse(item["link"]).netloc.replace("www.", "")
            content = item.get("content") or item.get("summary") or ""
            
            return {
                "id": item.get("id", ""),
                "title": item["title"],
                "content": content,
                "link": item["link"],
                "date": item["date"],
                "source": source
            }
    
    raise HTTPException(status_code=404, detail="Article not found")

def summarize_news(text: str, word_count: int = 70) -> str:
    print(f"ğŸ¤– [DEBUG] summarize_news called with text length: {len(text)}")
    print(f"ğŸ¤– [DEBUG] Text preview: {text[:300]}...")
    
    if not text.strip():
        print("âŒ [ERROR] Empty text passed to summarize_news!")
        return "No content available for summarization"
    
    prompt = (
        "Read the whole article and summarize this news in at least 420 characters "
        "and more than 65 words. Be as detailed as possible. Do not just copy and paste content."
        "Do not mention the source, outlet, or 'the article'. Just summarize the core content.\n\n"
        f"{text}"
    )
    try:
        resp = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=word_count * 2,
            temperature=0.5,
        )
        content = resp.choices[0].message.content
        result = content.strip() if content else "generation failed"
        print(f"âœ… [DEBUG] Generated summary: {result[:100]}...")
        return result
    except Exception as e:
        print(f"âŒ [ERROR] OpenAI summarize error: {e}")
        return "generation failed"


def score_news(text: str) -> int:
    """
    ç”¨ GPT ç»™æ–°é—»æ‰“åˆ†ï¼ˆ1-10åˆ†ï¼‰ï¼Œåˆ†æ•°è¶Šé«˜ä»£è¡¨è¶Šæœ‰ä»·å€¼/å¯è¯»æ€§ã€‚
    """
    prompt = (
    "You are an experienced journalist working for a major international news outlet like BBC or CNN.\n"
    "Please read the following news article and give it an importance score from 1 to 10,\n"
    "where 10 means extremely important and globally relevant, and 1 means very minor or trivial.\n\n"
    "Consider factors such as:\n"
    "- Global political or economic impact\n"
    "- Urgency and timeliness\n"
    "- Public interest and relevance\n"
    "- Societal consequences\n"
    "- Scope of affected population\n\n"
    "Respond with a single integer only, no explanation.\n\n"
        f"{text}"
    )
    try:
        resp = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=10,
            temperature=0.2,
        )
        score_str = resp.choices[0].message.content.strip() if resp.choices[0].message.content else "5"
        score = int(''.join(filter(str.isdigit, score_str)))
        return max(1, min(score, 10))
    except Exception as e:
        print("OpenAI score error:", e)
        return 5  # è¿”å›é»˜è®¤åˆ†æ•°è€Œä¸æ˜¯None